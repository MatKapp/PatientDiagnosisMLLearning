{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.read_csv(\"../data/tia-ed-sel-imp-2020-01-09.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>my_outcome</th>\n",
       "      <th>adj_outcome_is7day</th>\n",
       "      <th>adj_carotidoutcome_is7day</th>\n",
       "      <th>sex_female</th>\n",
       "      <th>age</th>\n",
       "      <th>temperature</th>\n",
       "      <th>hr_rate</th>\n",
       "      <th>sbp</th>\n",
       "      <th>dbp</th>\n",
       "      <th>sa02</th>\n",
       "      <th>...</th>\n",
       "      <th>my_vertigo_syncope</th>\n",
       "      <th>my_lang_speech</th>\n",
       "      <th>my_afib</th>\n",
       "      <th>img_abn_l</th>\n",
       "      <th>img_abn_r</th>\n",
       "      <th>uni_weakness_l</th>\n",
       "      <th>uni_weakness_r</th>\n",
       "      <th>aphasia</th>\n",
       "      <th>peter_flag</th>\n",
       "      <th>learn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>53.0</td>\n",
       "      <td>36.299988</td>\n",
       "      <td>70.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>81.0</td>\n",
       "      <td>36.500000</td>\n",
       "      <td>57.0</td>\n",
       "      <td>215.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>36.599976</td>\n",
       "      <td>66.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>35.199980</td>\n",
       "      <td>108.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>97.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>74.0</td>\n",
       "      <td>36.799988</td>\n",
       "      <td>110.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   my_outcome  adj_outcome_is7day  adj_carotidoutcome_is7day  sex_female  \\\n",
       "0           0                   0                        0.0           1   \n",
       "1           0                   0                        0.0           1   \n",
       "2           0                   0                        0.0           0   \n",
       "3           0                   0                        0.0           0   \n",
       "4           0                   0                        0.0           1   \n",
       "\n",
       "    age  temperature  hr_rate    sbp   dbp  sa02  ...  my_vertigo_syncope  \\\n",
       "0  53.0    36.299988     70.0  121.0  79.0  99.0  ...                   0   \n",
       "1  81.0    36.500000     57.0  215.0  55.0  98.0  ...                   0   \n",
       "2  45.0    36.599976     66.0  151.0  95.0  98.0  ...                   0   \n",
       "3  54.0    35.199980    108.0  123.0  89.0  97.5  ...                   0   \n",
       "4  74.0    36.799988    110.0  119.0  79.0  98.0  ...                   0   \n",
       "\n",
       "   my_lang_speech  my_afib  img_abn_l  img_abn_r  uni_weakness_l  \\\n",
       "0               0        0          0          0               0   \n",
       "1               1        0          0          0               0   \n",
       "2               0        0          0          0               0   \n",
       "3               1        0          0          0               0   \n",
       "4               1        1          0          0               0   \n",
       "\n",
       "   uni_weakness_r aphasia  peter_flag  learn  \n",
       "0               0       0           0      1  \n",
       "1               0       0           0      1  \n",
       "2               0       0           0      1  \n",
       "3               0       1           0      1  \n",
       "4               1       0           0      1  \n",
       "\n",
       "[5 rows x 53 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unused decision variables\n",
    "df_all.drop(columns=['adj_outcome_is7day', 'adj_carotidoutcome_is7day'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dursymptoms</th>\n",
       "      <th>dursymptoms_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ge_60min</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5_9min</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10_29min</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1_5min</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>30_59min</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>lt_1min</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dursymptoms  dursymptoms_encoded\n",
       "0     ge_60min                    5\n",
       "1       5_9min                    2\n",
       "7     10_29min                    3\n",
       "10      1_5min                    1\n",
       "12    30_59min                    4\n",
       "63     lt_1min                    0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all['dursymptoms_encoded'] = df_all.dursymptoms.map({'lt_1min': 0, '1_5min': 1, '5_9min': 2, '10_29min': 3, '30_59min': 4, 'ge_60min': 5})\n",
    "df_all[['dursymptoms', 'dursymptoms_encoded']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now remove the old dursymptoms columns and rename dursymptoms_encoded to dursymptoms\n",
    "df_all.drop(columns=['dursymptoms'], inplace=True)\n",
    "df_all.rename(columns={'dursymptoms_encoded': 'dursymptoms'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We also change the type of inittia_numpast from float to int\n",
    "df_all.inittia_numpast = pd.to_numeric(df_all.inittia_numpast, downcast='integer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Introduce dummy variables\n",
    "df_all_encoded = pd.get_dummies(df_all, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into learning and training subsets\n",
    "df_train = df_all_encoded[df_all_encoded.learn == 1].drop(columns=['learn'])\n",
    "df_test = df_all_encoded[df_all_encoded.learn == 0].drop(columns=['learn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.iloc[:, 1:]\n",
    "y_train = df_train.iloc[:, 0]\n",
    "X_test = df_test.iloc[:, 1:]\n",
    "y_test = df_test.iloc[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex_female</th>\n",
       "      <th>age</th>\n",
       "      <th>temperature</th>\n",
       "      <th>hr_rate</th>\n",
       "      <th>sbp</th>\n",
       "      <th>dbp</th>\n",
       "      <th>sa02</th>\n",
       "      <th>wbcvalue</th>\n",
       "      <th>hgbvalue</th>\n",
       "      <th>pltvalue</th>\n",
       "      <th>...</th>\n",
       "      <th>med_clop_already_taken</th>\n",
       "      <th>med_clop_discont_ed</th>\n",
       "      <th>med_clop_started_ed</th>\n",
       "      <th>med_stat_discont_ed</th>\n",
       "      <th>med_stat_started_ed</th>\n",
       "      <th>med_anti_discont_ed</th>\n",
       "      <th>med_anti_started_ed</th>\n",
       "      <th>med_coum_already_taken</th>\n",
       "      <th>med_coum_discont_ed</th>\n",
       "      <th>med_coum_started_ed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>53.0</td>\n",
       "      <td>36.299988</td>\n",
       "      <td>70.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>238.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>81.0</td>\n",
       "      <td>36.500000</td>\n",
       "      <td>57.0</td>\n",
       "      <td>215.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>144.0</td>\n",
       "      <td>293.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>36.599976</td>\n",
       "      <td>66.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>10.3</td>\n",
       "      <td>162.0</td>\n",
       "      <td>316.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>35.199980</td>\n",
       "      <td>108.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>97.5</td>\n",
       "      <td>6.6</td>\n",
       "      <td>153.0</td>\n",
       "      <td>265.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>74.0</td>\n",
       "      <td>36.799988</td>\n",
       "      <td>110.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>7.9</td>\n",
       "      <td>153.0</td>\n",
       "      <td>463.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   sex_female   age  temperature  hr_rate    sbp   dbp  sa02  wbcvalue  \\\n",
       "0           1  53.0    36.299988     70.0  121.0  79.0  99.0       8.0   \n",
       "1           1  81.0    36.500000     57.0  215.0  55.0  98.0       8.3   \n",
       "2           0  45.0    36.599976     66.0  151.0  95.0  98.0      10.3   \n",
       "3           0  54.0    35.199980    108.0  123.0  89.0  97.5       6.6   \n",
       "4           1  74.0    36.799988    110.0  119.0  79.0  98.0       7.9   \n",
       "\n",
       "   hgbvalue  pltvalue  ...  med_clop_already_taken  med_clop_discont_ed  \\\n",
       "0     151.0     238.0  ...                       0                    0   \n",
       "1     144.0     293.0  ...                       0                    0   \n",
       "2     162.0     316.0  ...                       0                    0   \n",
       "3     153.0     265.0  ...                       0                    0   \n",
       "4     153.0     463.0  ...                       0                    0   \n",
       "\n",
       "   med_clop_started_ed  med_stat_discont_ed  med_stat_started_ed  \\\n",
       "0                    0                    0                    0   \n",
       "1                    0                    0                    1   \n",
       "2                    0                    0                    0   \n",
       "3                    0                    0                    0   \n",
       "4                    0                    0                    0   \n",
       "\n",
       "   med_anti_discont_ed  med_anti_started_ed  med_coum_already_taken  \\\n",
       "0                    0                    0                       0   \n",
       "1                    0                    0                       0   \n",
       "2                    0                    0                       0   \n",
       "3                    0                    1                       0   \n",
       "4                    0                    0                       0   \n",
       "\n",
       "   med_coum_discont_ed  med_coum_started_ed  \n",
       "0                    0                    0  \n",
       "1                    0                    0  \n",
       "2                    0                    0  \n",
       "3                    0                    0  \n",
       "4                    0                    1  \n",
       "\n",
       "[5 rows x 64 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['my_outcome', 'sex_female', 'age', 'temperature', 'hr_rate', 'sbp',\n",
       "       'dbp', 'sa02', 'wbcvalue', 'hgbvalue', 'pltvalue', 'creatinevalue',\n",
       "       'glucosevalue', 'ckvalue', 'tntvalue', 'pmedhis_hyp',\n",
       "       'pmedhis_cad', 'pmedhis_af', 'pmedhis_pvd', 'pmedhis_diab',\n",
       "       'pmedhis_kps', 'pmedhis_smoker', 'pmedhis_cs', 'pmedhis_chf',\n",
       "       'pmedhis_hchol', 'pmedhis_dem', 'pmedhis_vhd',\n",
       "       'med_ibup_last_7days', 'my_infarct', 'inittia_numpast',\n",
       "       'my_sensation', 'my_weakness', 'my_gait', 'my_vertigo_syncope',\n",
       "       'my_lang_speech', 'my_afib', 'img_abn_l', 'img_abn_r',\n",
       "       'uni_weakness_l', 'uni_weakness_r', 'aphasia', 'peter_flag',\n",
       "       'dursymptoms', 'my_ecgtype_afib', 'my_ecgtype_afl',\n",
       "       'my_ecgtype_conduction_abn', 'my_ecgtype_non_specific',\n",
       "       'my_ecgtype_old_infarct', 'my_ecgtype_pace_rhythm',\n",
       "       'my_ecgtype_sinus_rhythm', 'med_asa_discont_ed',\n",
       "       'med_asa_started_ed', 'med_dipy_already_taken',\n",
       "       'med_dipy_discont_ed', 'med_dipy_started_ed',\n",
       "       'med_clop_already_taken', 'med_clop_discont_ed',\n",
       "       'med_clop_started_ed', 'med_stat_discont_ed',\n",
       "       'med_stat_started_ed', 'med_anti_discont_ed',\n",
       "       'med_anti_started_ed', 'med_coum_already_taken',\n",
       "       'med_coum_discont_ed', 'med_coum_started_ed'], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['my_outcome', 'sex_female', 'age', 'temperature', 'hr_rate', 'sbp',\n",
       "       'dbp', 'sa02', 'wbcvalue', 'hgbvalue', 'pltvalue', 'creatinevalue',\n",
       "       'glucosevalue', 'ckvalue', 'tntvalue', 'pmedhis_hyp', 'pmedhis_cad',\n",
       "       'pmedhis_af', 'pmedhis_pvd', 'pmedhis_diab', 'pmedhis_kps',\n",
       "       'pmedhis_smoker', 'pmedhis_cs', 'pmedhis_chf', 'pmedhis_hchol',\n",
       "       'pmedhis_dem', 'pmedhis_vhd', 'med_ibup_last_7days', 'my_infarct',\n",
       "       'inittia_numpast', 'my_sensation', 'my_weakness', 'my_gait',\n",
       "       'my_vertigo_syncope', 'my_lang_speech', 'my_afib', 'img_abn_l',\n",
       "       'img_abn_r', 'uni_weakness_l', 'uni_weakness_r', 'aphasia',\n",
       "       'peter_flag', 'dursymptoms', 'my_ecgtype_afib', 'my_ecgtype_afl',\n",
       "       'my_ecgtype_conduction_abn', 'my_ecgtype_non_specific',\n",
       "       'my_ecgtype_old_infarct', 'my_ecgtype_pace_rhythm',\n",
       "       'my_ecgtype_sinus_rhythm', 'med_asa_discont_ed', 'med_asa_started_ed',\n",
       "       'med_dipy_already_taken', 'med_dipy_discont_ed', 'med_dipy_started_ed',\n",
       "       'med_clop_already_taken', 'med_clop_discont_ed', 'med_clop_started_ed',\n",
       "       'med_stat_discont_ed', 'med_stat_started_ed', 'med_anti_discont_ed',\n",
       "       'med_anti_started_ed', 'med_coum_already_taken', 'med_coum_discont_ed',\n",
       "       'med_coum_started_ed'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())])\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3891 entries, 3954 to 11507\n",
      "Data columns (total 65 columns):\n",
      "my_outcome                   3891 non-null int64\n",
      "sex_female                   3891 non-null int64\n",
      "age                          3891 non-null float64\n",
      "temperature                  3891 non-null float64\n",
      "hr_rate                      3891 non-null float64\n",
      "sbp                          3891 non-null float64\n",
      "dbp                          3891 non-null float64\n",
      "sa02                         3891 non-null float64\n",
      "wbcvalue                     3891 non-null float64\n",
      "hgbvalue                     3891 non-null float64\n",
      "pltvalue                     3891 non-null float64\n",
      "creatinevalue                3891 non-null float64\n",
      "glucosevalue                 3891 non-null float64\n",
      "ckvalue                      3891 non-null float64\n",
      "tntvalue                     3891 non-null float64\n",
      "pmedhis_hyp                  3891 non-null int64\n",
      "pmedhis_cad                  3891 non-null int64\n",
      "pmedhis_af                   3891 non-null int64\n",
      "pmedhis_pvd                  3891 non-null int64\n",
      "pmedhis_diab                 3891 non-null int64\n",
      "pmedhis_kps                  3891 non-null int64\n",
      "pmedhis_smoker               3891 non-null int64\n",
      "pmedhis_cs                   3891 non-null int64\n",
      "pmedhis_chf                  3891 non-null int64\n",
      "pmedhis_hchol                3891 non-null int64\n",
      "pmedhis_dem                  3891 non-null int64\n",
      "pmedhis_vhd                  3891 non-null int64\n",
      "med_ibup_last_7days          3891 non-null int64\n",
      "my_infarct                   3891 non-null int64\n",
      "inittia_numpast              3891 non-null int8\n",
      "my_sensation                 3891 non-null int64\n",
      "my_weakness                  3891 non-null int64\n",
      "my_gait                      3891 non-null int64\n",
      "my_vertigo_syncope           3891 non-null int64\n",
      "my_lang_speech               3891 non-null int64\n",
      "my_afib                      3891 non-null int64\n",
      "img_abn_l                    3891 non-null int64\n",
      "img_abn_r                    3891 non-null int64\n",
      "uni_weakness_l               3891 non-null int64\n",
      "uni_weakness_r               3891 non-null int64\n",
      "aphasia                      3891 non-null int64\n",
      "peter_flag                   3891 non-null int64\n",
      "dursymptoms                  3891 non-null int64\n",
      "my_ecgtype_afib              3891 non-null uint8\n",
      "my_ecgtype_afl               3891 non-null uint8\n",
      "my_ecgtype_conduction_abn    3891 non-null uint8\n",
      "my_ecgtype_non_specific      3891 non-null uint8\n",
      "my_ecgtype_old_infarct       3891 non-null uint8\n",
      "my_ecgtype_pace_rhythm       3891 non-null uint8\n",
      "my_ecgtype_sinus_rhythm      3891 non-null uint8\n",
      "med_asa_discont_ed           3891 non-null uint8\n",
      "med_asa_started_ed           3891 non-null uint8\n",
      "med_dipy_already_taken       3891 non-null uint8\n",
      "med_dipy_discont_ed          3891 non-null uint8\n",
      "med_dipy_started_ed          3891 non-null uint8\n",
      "med_clop_already_taken       3891 non-null uint8\n",
      "med_clop_discont_ed          3891 non-null uint8\n",
      "med_clop_started_ed          3891 non-null uint8\n",
      "med_stat_discont_ed          3891 non-null uint8\n",
      "med_stat_started_ed          3891 non-null uint8\n",
      "med_anti_discont_ed          3891 non-null uint8\n",
      "med_anti_started_ed          3891 non-null uint8\n",
      "med_coum_already_taken       3891 non-null uint8\n",
      "med_coum_discont_ed          3891 non-null uint8\n",
      "med_coum_started_ed          3891 non-null uint8\n",
      "dtypes: float64(13), int64(29), int8(1), uint8(22)\n",
      "memory usage: 1.4 MB\n"
     ]
    }
   ],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "numeric_features = X_train.select_dtypes(include=['int64', 'float64', 'uint8', 'int8']).columns\n",
    "categorical_features = X_train.select_dtypes(include=['object']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.under_sampling import NeighbourhoodCleaningRule\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.over_sampling import SMOTE, BorderlineSMOTE, ADASYN\n",
    "from imblearn.combine import SMOTEENN\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.metrics import auc, roc_curve, roc_auc_score\n",
    "\n",
    "import pickle\n",
    "\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "samplers = {\n",
    "#     \"None\": NoneSampler(),\n",
    "    \"RU\": RandomUnderSampler(random_state=42),\n",
    "    \"SMOTE\": SMOTE(random_state=42),\n",
    "#     \"BSMOTE\": BorderlineSMOTE(random_state=42),\n",
    "#     \"SMOTEENN\": SMOTEENN(random_state = 42),\n",
    "#     \"NCR\": NeighbourhoodCleaningRule(),\n",
    "#     \"RO\": RandomOverSampler(random_state=42),\n",
    "    \"ADASYN\": ADASYN(random_state=42)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = { \n",
    "#     \"1NN\": KNeighborsClassifier(1), \n",
    "#     \"3NN\": KNeighborsClassifier(3), \n",
    "#     \"AB\": AdaBoostClassifier(random_state=42),\n",
    "#     \"DT-G\": DecisionTreeClassifier(random_state=42, max_depth=10),\n",
    "#     \"DT-H\": DecisionTreeClassifier(random_state=42, criterion='entropy', max_depth=10),\n",
    "    \"LR\": LogisticRegression(random_state=42, solver='lbfgs', max_iter=500),\n",
    "    \"RF\": RandomForestClassifier(random_state=42, n_estimators=100, max_depth=5),\n",
    "#     \"SVC\": SVC(random_state=42, probability=True, gamma='auto'),\n",
    "#     \"LSVC\": SVC(random_state=42, kernel='linear', probability=True, class_weight='balanced'),\n",
    "#     \"XGB\": XGBClassifier(random_state=42)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(name, clf, X_test, y_test, X_train = None, y_train = None):\n",
    "    \"\"\"Fits and evaluates a classifier on a holdout sample\"\"\"\n",
    "    if not (X_train is None or y_train is None):\n",
    "        clf.fit(X_train, y_train)\n",
    "    pickle.dump(clf, open(f'{name}test.sav', 'wb'))\n",
    "    y_prob = clf.predict_proba(X_test)[:, 1]\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR\n",
      "RF\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for classifier_label, classifier in classifiers.items(): \n",
    "    print(classifier_label)\n",
    "    if not (X_train is None or y_train is None):\n",
    "        rf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                          ('classifier', classifier)])\n",
    "        rf.fit(X_train, y_train)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "group1 = ['pmedhis_hyp', 'pmedhis_cad', 'pmedhis_af', 'pmedhis_pvd', 'pmedhis_diab', 'pmedhis_kps', 'pmedhis_smoker', 'pmedhis_cs', 'pmedhis_chf', 'pmedhis_hchol', 'pmedhis_dem', 'pmedhis_vhd', 'med_ibup_last_7days', 'my_infarct', 'inittia_numpast']\n",
    "group1removed = ['med_clop', 'med_dipy', 'med_stat', 'med_anti', 'med_asa', 'med_coum']\n",
    "group2 = ['temperature', 'hr_rate', 'sbp', 'dbp', 'sa02', 'dursymptoms', 'my_sensation', 'my_weakness', 'my_gait', 'my_vertigo_syncope', 'my_lang_speech', 'my_afib', 'uni_weakness_l', 'uni_weakness_r', 'aphasia']\n",
    "group3 = ['peter_flag', 'wbcvalue', 'hgbvalue', 'pltvalue', 'creatinevalue', 'glucosevalue', 'ckvalue', 'tntvalue', 'img_abn_l', 'img_abn_r']\n",
    "group3removed = ['ecgtype']\n",
    "\n",
    "X_train[list(set(X_train.columns) - set(group1))]\n",
    "\n",
    "group1DataFrame = X_train[group1]\n",
    "group2DataFrame = X_train[group1 + group2]\n",
    "group3DataFrame = X_train[group1 + group2 + group3]\n",
    "\n",
    "groups = [group1DataFrame, group2DataFrame, group3DataFrame]\n",
    "test_group_1 = X_test.copy()\n",
    "test_group_1[group2 + group3] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kapis\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:440: FutureWarning: Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "  FutureWarning)\n",
      "c:\\users\\kapis\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:440: FutureWarning: Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "  FutureWarning)\n",
      "c:\\users\\kapis\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:440: FutureWarning: Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "  FutureWarning)\n",
      "c:\\users\\kapis\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:440: FutureWarning: Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "  FutureWarning)\n",
      "c:\\users\\kapis\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:440: FutureWarning: Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "  FutureWarning)\n",
      "c:\\users\\kapis\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:440: FutureWarning: Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "  FutureWarning)\n",
      "c:\\users\\kapis\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:440: FutureWarning: Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "  FutureWarning)\n",
      "c:\\users\\kapis\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:440: FutureWarning: Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "  FutureWarning)\n",
      "c:\\users\\kapis\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:440: FutureWarning: Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "  FutureWarning)\n",
      "c:\\users\\kapis\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:440: FutureWarning: Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "  FutureWarning)\n",
      "c:\\users\\kapis\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:440: FutureWarning: Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "  FutureWarning)\n",
      "c:\\users\\kapis\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:440: FutureWarning: Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "  FutureWarning)\n",
      "c:\\users\\kapis\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:440: FutureWarning: Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "  FutureWarning)\n",
      "c:\\users\\kapis\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:440: FutureWarning: Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 RF ADASYN 0.4479568234387047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kapis\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:440: FutureWarning: Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "  FutureWarning)\n",
      "c:\\users\\kapis\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:440: FutureWarning: Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "  FutureWarning)\n",
      "c:\\users\\kapis\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:440: FutureWarning: Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "  FutureWarning)\n",
      "c:\\users\\kapis\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:440: FutureWarning: Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "  FutureWarning)\n",
      "c:\\users\\kapis\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:440: FutureWarning: Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "  FutureWarning)\n",
      "c:\\users\\kapis\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:440: FutureWarning: Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "  FutureWarning)\n",
      "c:\\users\\kapis\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:440: FutureWarning: Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "  FutureWarning)\n",
      "c:\\users\\kapis\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:440: FutureWarning: Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "  FutureWarning)\n",
      "c:\\users\\kapis\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:440: FutureWarning: Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "  FutureWarning)\n",
      "c:\\users\\kapis\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:440: FutureWarning: Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 RF ADASYN 0.32099717296324853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kapis\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:440: FutureWarning: Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "  FutureWarning)\n",
      "c:\\users\\kapis\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:440: FutureWarning: Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "  FutureWarning)\n",
      "c:\\users\\kapis\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:440: FutureWarning: Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "  FutureWarning)\n",
      "c:\\users\\kapis\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:440: FutureWarning: Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "  FutureWarning)\n",
      "c:\\users\\kapis\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:440: FutureWarning: Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "  FutureWarning)\n",
      "c:\\users\\kapis\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:440: FutureWarning: Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "  FutureWarning)\n",
      "c:\\users\\kapis\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:440: FutureWarning: Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "  FutureWarning)\n",
      "c:\\users\\kapis\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:440: FutureWarning: Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "  FutureWarning)\n",
      "c:\\users\\kapis\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:440: FutureWarning: Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "  FutureWarning)\n",
      "c:\\users\\kapis\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:440: FutureWarning: Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 RF ADASYN 0.34489848368028786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kapis\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:440: FutureWarning: Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "  FutureWarning)\n",
      "c:\\users\\kapis\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:440: FutureWarning: Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for num, group in enumerate(groups):\n",
    "    best_pipeline = None\n",
    "    group_best_label = ''\n",
    "    group_best = 0\n",
    "    for classifier_label, classifier in classifiers.items():\n",
    "        for sampler_label, sampler in samplers.items():\n",
    "\n",
    "            if not (group is None or y_train is None):\n",
    "\n",
    "                X_over, y_over = sampler.fit_resample(group, y_train)\n",
    "                \n",
    "                numeric_features = group.select_dtypes(include=['int64', 'float64', 'uint8', 'int8']).columns\n",
    "                categorical_features = group.select_dtypes(include=['object']).columns\n",
    "                preprocessor = ColumnTransformer(\n",
    "                    transformers=[\n",
    "                        ('num', numeric_transformer, numeric_features),\n",
    "                        ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "                rf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                                  ('classifier', classifier)])\n",
    "                rf.fit(X_over, y_over)\n",
    "\n",
    "                y_prob = rf.predict_proba(test_group_1)[:, 1]\n",
    "                y_pred = rf.predict(test_group_1)\n",
    "                score = accuracy_score(y_test, y_pred)\n",
    "                \n",
    "                if (score > group_best):\n",
    "                    group_best_label = f'{num} {classifier_label} {sampler_label} {score}'\n",
    "                    best_pipeline = rf\n",
    "    print (group_best_label)\n",
    "    pickle.dump(rf, open(f'{group_best_label}.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sex_female', 'age', 'temperature', 'hr_rate', 'sbp', 'dbp', 'sa02',\n",
       "       'wbcvalue', 'hgbvalue', 'pltvalue', 'creatinevalue', 'glucosevalue',\n",
       "       'ckvalue', 'tntvalue', 'pmedhis_hyp', 'pmedhis_cad', 'pmedhis_af',\n",
       "       'pmedhis_pvd', 'pmedhis_diab', 'pmedhis_kps', 'pmedhis_smoker',\n",
       "       'pmedhis_cs', 'pmedhis_chf', 'pmedhis_hchol', 'pmedhis_dem',\n",
       "       'pmedhis_vhd', 'med_ibup_last_7days', 'my_infarct', 'inittia_numpast',\n",
       "       'my_sensation', 'my_weakness', 'my_gait', 'my_vertigo_syncope',\n",
       "       'my_lang_speech', 'my_afib', 'img_abn_l', 'img_abn_r', 'uni_weakness_l',\n",
       "       'uni_weakness_r', 'aphasia', 'peter_flag', 'dursymptoms',\n",
       "       'my_ecgtype_afib', 'my_ecgtype_afl', 'my_ecgtype_conduction_abn',\n",
       "       'my_ecgtype_non_specific', 'my_ecgtype_old_infarct',\n",
       "       'my_ecgtype_pace_rhythm', 'my_ecgtype_sinus_rhythm',\n",
       "       'med_asa_discont_ed', 'med_asa_started_ed', 'med_dipy_already_taken',\n",
       "       'med_dipy_discont_ed', 'med_dipy_started_ed', 'med_clop_already_taken',\n",
       "       'med_clop_discont_ed', 'med_clop_started_ed', 'med_stat_discont_ed',\n",
       "       'med_stat_started_ed', 'med_anti_discont_ed', 'med_anti_started_ed',\n",
       "       'med_coum_already_taken', 'med_coum_discont_ed', 'med_coum_started_ed'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf['preprocessor'].transformers_[0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.66368077, 0.33631923]])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = X_test.copy()\n",
    "test['peter_flag'] = None\n",
    "print(test.iloc[[13]].shape)\n",
    "rf.predict_proba(test.iloc[[13]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.full(64, dtype=float, fill_value=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64,)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Specifying the columns using strings is only supported for pandas DataFrames",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mEmpty\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\kapis\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    796\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 797\u001b[1;33m                 \u001b[0mtasks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ready_batches\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    798\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mqueue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEmpty\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kapis\\appdata\\local\\programs\\python\\python36\\lib\\queue.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    160\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_qsize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 161\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    162\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mEmpty\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-89-e7bfde7cd936>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mrf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\kapis\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m         \u001b[1;31m# lambda, but not partial, allows help() to work with update_wrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 119\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    120\u001b[0m         \u001b[1;31m# update the docstring of the returned function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m         \u001b[0mupdate_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kapis\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    461\u001b[0m         \u001b[0mXt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    462\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransform\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwith_final\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 463\u001b[1;33m             \u001b[0mXt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    464\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    465\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kapis\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    602\u001b[0m         \u001b[1;31m# TODO: also call _check_n_features(reset=False) in 0.24\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    603\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_feature_names\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 604\u001b[1;33m         \u001b[0mXs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_transform_one\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfitted\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    605\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    606\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kapis\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py\u001b[0m in \u001b[0;36m_fit_transform\u001b[1;34m(self, X, y, func, fitted)\u001b[0m\n\u001b[0;32m    465\u001b[0m                     message=self._log_message(name, idx, len(transformers)))\n\u001b[0;32m    466\u001b[0m                 for idx, (name, trans, column, weight) in enumerate(\n\u001b[1;32m--> 467\u001b[1;33m                         self._iter(fitted=fitted, replace_strings=True), 1))\n\u001b[0m\u001b[0;32m    468\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    469\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;34m\"Expected 2D array, got 1D array instead\"\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kapis\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1002\u001b[0m             \u001b[1;31m# remaining jobs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1003\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1004\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1005\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1006\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kapis\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    806\u001b[0m                 \u001b[0mbig_batch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    807\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 808\u001b[1;33m                 \u001b[0mislice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitertools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mislice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbig_batch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    809\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mislice\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    810\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kapis\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    464\u001b[0m                     \u001b[0mmessage_clsname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'ColumnTransformer'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    465\u001b[0m                     message=self._log_message(name, idx, len(transformers)))\n\u001b[1;32m--> 466\u001b[1;33m                 for idx, (name, trans, column, weight) in enumerate(\n\u001b[0m\u001b[0;32m    467\u001b[0m                         self._iter(fitted=fitted, replace_strings=True), 1))\n\u001b[0;32m    468\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kapis\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\utils\\__init__.py\u001b[0m in \u001b[0;36m_safe_indexing\u001b[1;34m(X, indices, axis)\u001b[0m\n\u001b[0;32m    386\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mindices_dtype\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'str'\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'loc'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    387\u001b[0m         raise ValueError(\n\u001b[1;32m--> 388\u001b[1;33m             \u001b[1;34m\"Specifying the columns using strings is only supported for \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    389\u001b[0m             \u001b[1;34m\"pandas DataFrames\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    390\u001b[0m         )\n",
      "\u001b[1;31mValueError\u001b[0m: Specifying the columns using strings is only supported for pandas DataFrames"
     ]
    }
   ],
   "source": [
    "rf.predict_proba([a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
